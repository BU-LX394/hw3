{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9103299-fdb9-4a7b-a438-c7f7917eb9f1",
   "metadata": {},
   "source": [
    "# HW 3: Spam vs. Ham\n",
    "\n",
    "In this homework assignment, you will implement, train, and test a na誰ve Bayes spam classifier on the [Enron Spam Dataset](https://www.kaggle.com/datasets/marcelwiechmann/enron-spam-data/data) [(Metsis et al., 2006)](https://www2.aueb.gr/users/ion/docs/ceas2006_paper.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c01a6ec-ac6c-4f78-a266-203ecf6e3f49",
   "metadata": {},
   "source": [
    "## Problem 0: Setup (0 Points in Total)\n",
    "\n",
    "Before beginning the assignment, you will need to download and examine the [Enron Spam Dataset](https://www.kaggle.com/datasets/marcelwiechmann/enron-spam-data/data), a dataset for spam classification created by [Metsis et al. (2006)](https://www2.aueb.gr/users/ion/docs/ceas2006_paper.pdf).\n",
    "\n",
    "### Problem 0a: Download Spam Dataset (No Submission, 0 Points)\n",
    "\n",
    "Please download the Enron Spam Dataset from the Assignments folder of Blackboard. The dataset consists of a single file, `enron_spam_data.csv`. Please put this file in the `data` subdirectory of this folder.\n",
    "\n",
    "### Problem 0b: Inspect Spam Dataset (No Submission, 0 Points)\n",
    "\n",
    "Please look at the `enron_spam_data.csv` file and examine its structure. You can open the file using Jupyter Notebook, Microsoft Excel, Google Sheets, or any plaintext editor (e.g., Notepad in Windows, TextEdit in Mac OS, or Text Editor in Linux). \n",
    "\n",
    "Notice that each line of this file represents an email. What information does the file contain about each email?\n",
    "\n",
    "Notice that the subject and message of each email have already been tokenized, with the tokens separated by spaces."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e07f4f-605f-4fc1-9027-5aea0912d5eb",
   "metadata": {},
   "source": [
    "## Problem 1: Python Exercises (5 Points in Total)\n",
    "\n",
    "In these exercises, you will learn and practice Python concepts needed in order to implement and test a na誰ve Bayes spam classifier in Problems 2 and 3.\n",
    "\n",
    "### Problem 1a: Understand Dict Disjunction (Written, 1 Point)\n",
    "\n",
    "Try running the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af5405e6-c09e-4e17-800d-810e8c4adc19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1, 'b': 2, 'c': 3, 'd': 4}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1 = {\"a\": 1, \"b\": 2}\n",
    "d2 = {\"c\": 3, \"d\": 4}\n",
    "d1 | d2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771b9f12-9342-4684-95d2-1eacced2db24",
   "metadata": {},
   "source": [
    "In general, if `d1` and `d2` are `dict`s, what is `d1 | d2`?\n",
    "\n",
    "### Problem 1b: Understand CSV Files (Written, 1 Point)\n",
    "\n",
    "Look at the file `data/sample_data.csv`. Please write down the data contained in this file, in the form of a table. Your table should look like the following:\n",
    "\n",
    "| col1 | col2 | col3 |\n",
    "|------|------|------|\n",
    "|   |   |   |\n",
    "|   |   |   |\n",
    "|   |   |   |\n",
    "|   |   |   |\n",
    "\n",
    "### Problem 1c: Understand the `csv` Module (No Submission, 0 Points)\n",
    "\n",
    "Try running the following code, and pay attention to what it does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d753188-a7fb-4297-a93e-23d6b716dad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['col1', 'col2', 'col3']\n",
      "['1', '2', '3']\n",
      "['4', '5', '6']\n",
      "['7', '8', '9']\n",
      "['10', '11', '12']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "with open(\"data/sample_data.csv\", \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bb175b-d0a4-4491-8e38-9c61632f080c",
   "metadata": {},
   "source": [
    "### Problem 1d: Skip Header Row (Written, 1 Point)\n",
    "\n",
    "The following cell is similar to the one from Problem 1c, but contains an extra line of code. What is this extra line of code, and what does it do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "381ad922-c2aa-473b-8660-03e2f66287cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '2', '3']\n",
      "['4', '5', '6']\n",
      "['7', '8', '9']\n",
      "['10', '11', '12']\n"
     ]
    }
   ],
   "source": [
    "with open(\"data/sample_data.csv\", \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    header = next(reader)\n",
    "    for row in reader:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54a1a0b-cff6-46c0-b19e-152e465bf454",
   "metadata": {},
   "source": [
    "**Hint 1:** Look at the title of this problem.\n",
    "\n",
    "**Hint 2:** Let's try looking at the contents of the `header` variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e09e6cf-407e-41f0-92b6-c853ba57abf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['col1', 'col2', 'col3']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ddea12-2c93-45c3-9309-4bffacf0959d",
   "metadata": {},
   "source": [
    "### Problem 1e: Load Data from CSV File (Code, 1 Point)\n",
    "\n",
    "Please implement the function `load_csv` in `hw3.py`. This function should load the data from `data/sample_data.csv` in the form of a `dict`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0041e899-dd85-4713-9502-25c232562d9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'col1': ['1', '4', '7', '10'],\n",
       " 'col2': ['2', '5', '8', '11'],\n",
       " 'col3': ['3', '6', '9', '12']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import hw3\n",
    "\n",
    "hw3.load_csv(\"data/sample_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee63189-47ee-4698-8ba1-4097a0c874ca",
   "metadata": {},
   "source": [
    "**Hint:** You may find it helpful to look at Problem 1f, though you don't have to.\n",
    "\n",
    "### Problem 1f: Remember the `zip` Function (No Submission, 0 Points)\n",
    "\n",
    "Recall that the `zip` function combines two `list`s into a `list` of `tuple`s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3241a30d-7eed-4d60-b1d9-f1b948101e92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 1), ('b', 2), ('c', 3)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1 = [\"a\", \"b\", \"c\"]\n",
    "l2 = [1, 2, 3]\n",
    "list(zip(l1, l2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e3fcbc-a43b-4da0-8b45-0939fe65e811",
   "metadata": {},
   "source": [
    "Recall that you can \"unzip\" a list of tuples by using `zip` with a `*`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e8e50ad-04af-43dc-8f33-92164da4590b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 'b', 'c'), (1, 2, 3)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l3 = [(\"a\", 1), (\"b\", 2), (\"c\", 3)]\n",
    "list(zip(*l3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c0b4c6-4f9b-4f28-bbb3-e04c6c943e3b",
   "metadata": {},
   "source": [
    "### Problem 1g: Understand Variable Unpacking (Written, 1 Point)\n",
    "\n",
    "In each of the following code cells, what do the variables `x`, `y`, and `z` contain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0478537-b730-4fc5-aaa1-8a3f4dd022a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code cell 1\n",
    "x, y, z = 1, 2, 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a685c200-4d17-4e6b-9b31-0fdbb5ac90b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code cell 2\n",
    "x, y, z = l3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1b19898-ff74-44a6-80b0-e31527b0b133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a, 1\n",
      "b, 2\n",
      "c, 3\n"
     ]
    }
   ],
   "source": [
    "# Code cell 3\n",
    "for x, y in zip(l1, l2):\n",
    "    print(x, y, sep=\", \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45060b93-30c5-42fb-a40f-2eed316d5d93",
   "metadata": {},
   "source": [
    "In general, how do you set multiple variables at the same time, in one line of code?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ee7234-aa4b-449b-9b81-b9ece137a2d9",
   "metadata": {},
   "source": [
    "## Problem 2: Implement Spam Classifier (12 Points in Total)\n",
    "\n",
    "In this problem, you will complete the implementation of a na誰ve Bayes spam classifier.\n",
    "\n",
    "### Problem 2a: Deserialize Spam Dataset (Code, 2 Points)\n",
    "\n",
    "Please implement the function `hw3.load_spam_data`, which loads the Enron Spam Dataset into Python. The process of converting data from a file into Python objects is called [_deserialization_](https://en.wikipedia.org/wiki/Serialization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "377d3cba-204c-4547-a91d-1832cff936f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deserialize the Enron Spam Dataset\n",
    "emails = hw3.load_spam_data(\"data/enron_spam_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79f2b1f-bb2c-435f-ad4b-377d269a9650",
   "metadata": {},
   "source": [
    "The function should represent the dataset as a `list` of emails, where each email is represented as a `dict` with the following information:\n",
    "```python\n",
    "{\"subject\": [\"Office\", \"Hours\", \"?\"],  # The subject of the email\n",
    " \"message\": [\"Hi\", \"Yulu\", \",\", \"I\", \"need\", \"help\", ...],  # The contents of the email\n",
    " \"label\": \"ham\"}\n",
    "```\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "062e7018-df13-4f55-99a3-0acf445cb739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subject': ['calpine', 'daily', 'gas', 'nomination'],\n",
       " 'message': ['-', 'calpine', 'daily', 'gas', 'nomination', '1', '.', 'doc'],\n",
       " 'label': 'ham'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at an email\n",
    "emails[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0c8a04-dd3d-4563-92c7-97c87522eea4",
   "metadata": {},
   "source": [
    "**Hint 1:** Use the `String.split` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d178a606-3543-4862-9207-cbf78e946fa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', 'world', '!']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Hello world !\".split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425f9cc5-c94e-4198-81d4-9cd310020154",
   "metadata": {},
   "source": [
    "**Hint 2:** In order to load the emails, you will need to run the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e51b1176-b4da-4e6f-aa96-716c9a0570aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9223372036854775807"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "csv.field_size_limit(sys.maxsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285897dc-fcc6-4b5e-a8e2-4eb3253ad701",
   "metadata": {},
   "source": [
    "The `csv` module has a limit on the length of each column of a CSV file. Some of the emails in the Enron Spam Dataset are longer than the default maximum length, so the above code sets the length limit to the maximum possible value. The `hw3.py` file already has this code inside of it, but you will need to run the above cell if you choose to write a version of your function in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffd01ad-8f8e-4995-89f9-b1235298a284",
   "metadata": {},
   "source": [
    "### Problem 2b: Extract Common Token Types (Code, 2 Points)\n",
    "\n",
    "Please implement the function `hw3.get_vocab`, which extracts the $n$ most common token types (i.e., words) in a list of emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75481ad2-64f4-4a04-80a2-8f15288c6f9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.', '/', ':', ';', 'date', 'fw', 'hour', 'hourahead', 're', 'start'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The 10 most common token types in email subjects\n",
    "hw3.get_vocab(emails, \"subject\", n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97cd5b35-b178-485a-9fa8-30bdabcd6c00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{',', '-', '.', '/', ':', 'a', 'and', 'of', 'the', 'to'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The 10 most common token types in email messages\n",
    "hw3.get_vocab(emails, \"message\", n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e94d1a-7e54-4435-944e-af25e4d202ef",
   "metadata": {},
   "source": [
    "If no argument is provided for the parameter `n`, then all token types should be extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7b2aa52-9d38-40c2-bda4-c687f4166ec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7543"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many unique tokens appear in email subjects?\n",
    "len(hw3.get_vocab(emails, \"subject\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5180acf9-87a3-4356-9dff-cbcffa062c18",
   "metadata": {},
   "source": [
    "### Problem 2c: Extract Features from Emails (Code, 2 Points)\n",
    "\n",
    "Please implement the function `hw3.get_features`, which extracts binary unigram features from an email.\n",
    "\n",
    "There are two kinds of features that might be extracted:\n",
    "- `subject_contains(w)`, which indicates whether the email's subject contains at least one `w`\n",
    "- `message_contains(w)`, which indicates whether the email's message contains at least one `w`.\n",
    "\n",
    "The features of an email are represented as a `dict` in the following format:\n",
    "```python\n",
    "{\"subject_contains(Re:)\": True,\n",
    " \"subject_contains(Fwd:)\": False,\n",
    " \"subject_contains(Hello)\": True,\n",
    " ...,\n",
    " \"message_contains(The)\": True,\n",
    " \"message_contains(of)\": True,\n",
    " \"message_contains(in)\": False,\n",
    " ...}\n",
    "```\n",
    "where the keys of the `dict` (i.e., the possible features of the email) are indicated by the parameters `subj_vocab` and `msg_vocab`.\n",
    "\n",
    "For example, the following code extracts binary unigram features representing the five most common token types in email subjects and messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0144735a-d14a-493a-ba09-0345aabe9dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the 5 most common subject and message tokens\n",
    "subj_vocab = hw3.get_vocab(emails, \"subject\", n=5)\n",
    "msg_vocab = hw3.get_vocab(emails, \"message\", n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "857dc246-5bf3-4e90-9001-6bea34fbb356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subject_contains(.)': True,\n",
       " 'subject_contains(/)': False,\n",
       " 'subject_contains(;)': False,\n",
       " 'subject_contains(re)': False,\n",
       " 'subject_contains(:)': False,\n",
       " 'message_contains(.)': True,\n",
       " 'message_contains(:)': True,\n",
       " 'message_contains(,)': True,\n",
       " 'message_contains(the)': True,\n",
       " 'message_contains(-)': True}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract binary unigram features from an email\n",
    "hw3.get_features(emails[1], subj_vocab, msg_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b3d808-2b1f-460b-9036-91e53d1e4078",
   "metadata": {},
   "source": [
    "### Problem 2d: Preprocess Datasets (Code, 2 Points)\n",
    "\n",
    "The `hw3.SpamClassifier` class represents a na誰ve Bayes spam classifier. We construct a `SpamClassifier` by specifying what subject and message features we would like to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7008167a-150f-4f38-8375-347703234308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a SpamClassifier using 5 subject and message features\n",
    "classifier = hw3.SpamClassifier(subj_vocab, msg_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8a27e9-9a10-45cd-919c-456fcff6abc8",
   "metadata": {},
   "source": [
    "Please implement the method `hw3.SpamClassifier.preprocess`, which converts a `list` of emails into the features of those emails, along with the classification label (`\"ham\"` or `\"spam\"`) of each email. Usage examples are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e995f14b-c40a-42f4-a58c-14c648c05e0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'subject_contains(.)': False,\n",
       "   'subject_contains(/)': False,\n",
       "   'subject_contains(;)': False,\n",
       "   'subject_contains(re)': False,\n",
       "   'subject_contains(:)': False,\n",
       "   'message_contains(.)': False,\n",
       "   'message_contains(:)': False,\n",
       "   'message_contains(,)': False,\n",
       "   'message_contains(the)': False,\n",
       "   'message_contains(-)': False},\n",
       "  'ham'),\n",
       " ({'subject_contains(.)': True,\n",
       "   'subject_contains(/)': False,\n",
       "   'subject_contains(;)': False,\n",
       "   'subject_contains(re)': False,\n",
       "   'subject_contains(:)': False,\n",
       "   'message_contains(.)': True,\n",
       "   'message_contains(:)': True,\n",
       "   'message_contains(,)': True,\n",
       "   'message_contains(the)': True,\n",
       "   'message_contains(-)': True},\n",
       "  'ham'),\n",
       " ({'subject_contains(.)': False,\n",
       "   'subject_contains(/)': False,\n",
       "   'subject_contains(;)': False,\n",
       "   'subject_contains(re)': False,\n",
       "   'subject_contains(:)': False,\n",
       "   'message_contains(.)': True,\n",
       "   'message_contains(:)': False,\n",
       "   'message_contains(,)': False,\n",
       "   'message_contains(the)': False,\n",
       "   'message_contains(-)': True},\n",
       "  'ham')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocess some ham emails\n",
    "classifier.preprocess(emails[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c7bcbf0c-7fc6-4a91-af30-2280db4336b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'subject_contains(.)': True,\n",
       "   'subject_contains(/)': False,\n",
       "   'subject_contains(;)': False,\n",
       "   'subject_contains(re)': True,\n",
       "   'subject_contains(:)': True,\n",
       "   'message_contains(.)': True,\n",
       "   'message_contains(:)': True,\n",
       "   'message_contains(,)': True,\n",
       "   'message_contains(the)': True,\n",
       "   'message_contains(-)': True},\n",
       "  'spam'),\n",
       " ({'subject_contains(.)': True,\n",
       "   'subject_contains(/)': False,\n",
       "   'subject_contains(;)': False,\n",
       "   'subject_contains(re)': True,\n",
       "   'subject_contains(:)': True,\n",
       "   'message_contains(.)': True,\n",
       "   'message_contains(:)': True,\n",
       "   'message_contains(,)': True,\n",
       "   'message_contains(the)': True,\n",
       "   'message_contains(-)': True},\n",
       "  'spam')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocess some spam emails\n",
    "classifier.preprocess(emails[-2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7481e633-cc78-44f7-88d8-cd0535b458ab",
   "metadata": {},
   "source": [
    "### Problem 2e: Evaluate Spam Classifier (Code, 4 Points)\n",
    "\n",
    "Please implement the method `hw3.SpamClassifier.evaluate`, which computes the `SpamClassifier`'s accuracy, precision, recall, and $F_1$ score on a list of emails. The results of the evaluation should be reported as a `dict` in the following format:\n",
    "```python\n",
    "{\"accuracy\": .78,  # These numbers are fake\n",
    " \"precision\": .727,\n",
    " \"recall\": .851,\n",
    " \"f1\": .784}\n",
    "```\n",
    "\n",
    "Recall that the definitions of precision, recall, and $F_1$ score require one of the classes to be defined as the \"positive label\" and the other classes to be defined as the \"negative label.\" For the `SpamClassifier.evaluate` method, the positive label is indicated by the class-level property `SpamClassifier.positive`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5920d507-000b-459c-a6a5-8ae073627c8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spam'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hw3.SpamClassifier.positive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdff2eb-2565-4295-b6a4-7733369f0468",
   "metadata": {},
   "source": [
    "The `SpamClassifier` has a property called `.model`, which the constructor (i.e., the `SpamClassifier.__init__` method) initializes to `None`. When the method `SpamClassifier.train` is called, an `nltk.NaiveBayesClassifier` is trained on the dataset provided, and the trained model is saved to `SpamClassifier.model`. This is the model your `SpamClassifier.evaluate` method should evaluate.\n",
    "\n",
    "To illustrate how the method works, let's now look at a usage example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8dbf67de-32e0-4552-886c-2802113105e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a small train and test set\n",
    "import random\n",
    "\n",
    "random.seed(10)\n",
    "random.shuffle(emails)\n",
    "\n",
    "train = emails[:100]\n",
    "test = emails[100:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "06e308fc-8660-45f4-925d-71f7560ae383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<nltk.classify.naivebayes.NaiveBayesClassifier at 0x78c58c5b2120>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a naive Bayes classifier\n",
    "classifier.train(train)\n",
    "\n",
    "# Notice that the naive Bayes classifier is saved to classifier.model\n",
    "classifier.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "22fdd705-5486-4873-8daa-c44bab047398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.73,\n",
       " 'precision': 0.7636363636363637,\n",
       " 'recall': 0.75,\n",
       " 'f1': 0.7567567567567568}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the trained naive Bayes classifier\n",
    "classifier.evaluate(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4abd07a3-32fd-44ba-adcc-69661957668c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's confirm that the accuracy matches NLTK's built-in code for accuracy\n",
    "import nltk\n",
    "\n",
    "nltk.classify.accuracy(classifier.model, classifier.preprocess(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec527df-39bc-4582-b5e2-600946489ea3",
   "metadata": {},
   "source": [
    "**Hint 1:** Let $\\textsf{tp}$, $\\textsf{tn}$, $\\textsf{fp}$, and $\\textsf{fn}$ be the number of true positive, true negative, false positive, and false negative predictions made by a model on a test set, respectively. The accuracy, precision, recall, and F1 scores can be calculated as follows.\n",
    "$$\\begin{align*}\n",
    "    \\text{accuracy} &= \\frac{\\textsf{tp} + \\textsf{tn}}{\\textsf{tp} + \\textsf{tn} + \\textsf{fp} + \\textsf{fn}} \\\\\n",
    "    \\text{precision} &= \\frac{\\textsf{tp}}{\\textsf{tp} + \\textsf{fp}} \\\\\n",
    "    \\text{recall} &= \\frac{\\textsf{tp}}{\\textsf{tp} + \\textsf{fn}} \\\\\n",
    "    F_1 &= \\frac{2\\textsf{tp}}{2\\textsf{tp} + \\textsf{fp} + \\textsf{fn}}\n",
    "\\end{align*}$$\n",
    "\n",
    "**Hint 2:** Recall that you can add a `bool` to an `int`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aba3668e-777f-40f3-97f5-c71b51690196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3 + True  # True == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "472f075e-0abc-41f2-ad4d-012e250e72c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2 + False  # False == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c25024-6304-4419-800e-1dff36661b39",
   "metadata": {},
   "source": [
    "**Hint 3:** You can use the `nltk.NaiveBayesClassifier.classify` method to predict a label using the model, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "730e2420-9776-4027-9629-33c06f100880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spam'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take an email from the test set and preprocess it\n",
    "test_email = classifier.preprocess(test[0:1])\n",
    "x, y = test_email[0]\n",
    "\n",
    "# Predict a label for x\n",
    "classifier.model.classify(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1a9949a9-82b7-4349-8729-ad5e24fe4e9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ham'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Was it correct?\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1222c2b9-493b-4815-8f7d-f4194cdeca19",
   "metadata": {},
   "source": [
    "**Hint 4:** Look at Problems 1f and 1g.\n",
    "\n",
    "**Hint 5:** If you'd like, you may use any built-in NLTK functions you find that compute the four metrics. However, it's probably easier just to compute the metrics yourself. Python libraries other than NLTK and the default libraries may or may not be available on the Gradescope autograder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1fbc65-f1f5-40f1-a391-efdc4403c53c",
   "metadata": {},
   "source": [
    "## Problem 3: Test Spam Classifier (3 Points in Total)\n",
    "\n",
    "Once you have finished implementing the `SpamClassifier`, you will test your classifier using the full Enron Spam Dataset.\n",
    "\n",
    "### Problem 3a: Run Experiment (No Submission, 1 Point)\n",
    "\n",
    "Please train and evaluate your `SpamClassifier` by running `hw3.py` as a script. To do so, navigate to this directory using Terminal (Mac OS/Linux) or Anaconda Prompt (Windows), and run the following code:\n",
    "```bash\n",
    "python hw3.py\n",
    "```\n",
    "\n",
    "Alternatively, you can run `hw3.py` from this notebook by running the following code cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "53b938ee-3104-4296-85e6-1bdad8a7285a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python hw3.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26aa5ea2-0b04-41b2-8067-87bfbcd1c48d",
   "metadata": {},
   "source": [
    "The `hw3.py` script splits the Enron Spam Dataset into training, development, and test sets. It will train three different `SpamClassifiers`:\n",
    "- a model that uses 500 subject features and 2000 message features\n",
    "- a model that uses the subject features only\n",
    "- a model that uses the message features only.\n",
    "\n",
    "The three models are then evaluated on the development set, and the model that achieves the highest $F_1$ score is evaluated on the test set.\n",
    "\n",
    "**Hint 1:** The script should take roughly 15 minutes to run.\n",
    "\n",
    "**Hint 2:** You do not need to submit anything for this problem, and you do not need to declare or provide evidence of actually having run the script. You will receive full credit for this problem no matter what.\n",
    "\n",
    "### Problem 3b: Report Results (Written, 1 Point)\n",
    "\n",
    "Please report the results of the experiment by filling in the following table.\n",
    "\n",
    "| Model Type | Dataset | Accuracy | Precision | Recall | F1 |\n",
    "|------------|---------|----------|-----------|--------|----|\n",
    "| Subject + Message | Dev |   |   |   |   |\n",
    "| Subject Only      | Dev |   |   |   |   |\n",
    "| Message Only      | Dev |   |   |   |   |\n",
    "|                   | Test |   |   |   |   |\n",
    "\n",
    "### Problem 3c: Analyze Results (Written, 1 Point)\n",
    "\n",
    "Please answer the following questions, based on the results reported in Problem 3b as well as the 5 most informative features of each model.\n",
    "- Which part of the email is more useful for spam classification: the subject or the message?\n",
    "- If a spam classifier already has access to the message of an email, is there much additional benefit to also having the email's subject?\n",
    "- It seems that there are many features that provide evidence that an email is spam, but few or no features that provide evidence that an email is ham. Why do you think this is?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
